---
layout: post
title: "ARM架构"
category: kernel
date: 2024-08-06 21:00:00 +0800
---

## ARM cache和MMU

参考：<https://aijishu.com/a/1060000000456118>

在ARM架构中，L1 cache都是VIPT的，也就是当有一个虚拟地址送进来，MMU在开始进行地址翻译的时候，Virtual Index就可以去L1 cache中查询了，MMU查询和L1 cache的index查询是同时进行的。如果L1 Miss了，则再去查询L2，L2还找不到则再去查询L3。 注意在arm架构中，仅仅L1是VIPT，L2和L3都是PIPT。ARM的cache是弱一致性的，而x86的cache是强一致性的（强一致性：cache更新后，后续的读取为更新后的值；弱一致性：cache更新后，后续读取的值可能是更新前的值，也可能是更新后的值。）

<img src="https://github.com/Geass-LL/draw/raw/master/github-io/ARM-cache-MMU.png" style="zoom:50%" />

## cacheline

通过`cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size`获取CPU某一级cache的cacheline大小。一般是64。

cacheline更新时为整行更新，所以如果cacheline比较大可能导致cacheline伪共享，引起性能下降：

<https://www.cnblogs.com/diegodu/p/9340243.html>

* cache在不同的CPU之间有多个副本
* A CPU更新自己的cache，修改cacheline的位置A，更新后标记B CPU的cache Invalidate
* B CPU实际上只关注cacheline的位置B，但是因为检测到Invalidate后发生cachemiss

### Direct mapped cache

<https://blog.csdn.net/rong_toa/article/details/109274448>

在CPU需要访问内存时，根据内存地址首先计算cacheline的索引（取模），然后检查cacheline是否有效（Valid Bit）、是否为预期的内存（Tag）。如果是，根据CPU指定的offset获取对应的数据。

<img src="https://github.com/Geass-LL/draw/raw/master/github-io/direct-mapped-cache.png" style="zoom:50%" />

### Cache Ways

每个cacheline可以同时映射到多个Ways，有助于减少Cache冲突。

粗略地理解不保证正确：一个Cacheline例如包含64Bytes，如果映射到8Ways，在修改Cacheline的前8Bytes时，可以去修改0-Way，标记0Way的Cacheline无效。此时再去读取Cacheline的后8Bytes时，在1-7Way可以匹配成功。这样做牺牲了Cache的大小降低了冲突。

<https://coolshell.cn/articles/20793.html>

### CCI-400

Armv8 CCI-400(Cache Coherent Interface)用于cluster之间的cache一致性保护。对于一个8核处理器，4个Cortex-A57组成cluster A，4个Cortex-A53组成culster B。在Cortex-A53发起一个Coherent都请求时，CCI-400会snoop Cortex-A57 cluster A的cache，如果cluster A中的cache数据可用，CCI-400会将数据从cluster A搬移到cluster B，实现cache填充。

## TLB

<https://github.com/carloscn/blog/issues/60>

* uTLB: I-side(L1-icache): 48
* uTLB: D-side(L1-dcache): 32
* Main TLB(L2-cache): 1024

为了避免flush整个TLB带来的性能损失，ARM将TLB分为全局TLB和局部TLB。（ASID技术，进程切换时通过ASID判断是否需要刷新TLB）
